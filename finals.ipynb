{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d16598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f3cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f4c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00377f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\DELL\\Desktop\\final_datasets\\dataset2\\accepted_2007_to_2018Q4.csv.gz', compression='gzip', low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2712b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.read_csv(r'C:\\Users\\DELL\\Desktop\\final_datasets\\dataset2\\rejected_2007_to_2018Q4.csv.gz', low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22679f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_accepted=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495cf033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2015</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>PA</td>\n",
       "      <td>5.91</td>\n",
       "      <td>677.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2015</td>\n",
       "      <td>small_business</td>\n",
       "      <td>SD</td>\n",
       "      <td>16.06</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2015</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>IL</td>\n",
       "      <td>10.78</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>3 years</td>\n",
       "      <td>2015</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>PA</td>\n",
       "      <td>25.37</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>4 years</td>\n",
       "      <td>2015</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>GA</td>\n",
       "      <td>10.20</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt emp_length  issue_d             purpose addr_state    dti  \\\n",
       "0     3600.0  10+ years     2015  debt_consolidation         PA   5.91   \n",
       "1    24700.0  10+ years     2015      small_business         SD  16.06   \n",
       "2    20000.0  10+ years     2015    home_improvement         IL  10.78   \n",
       "4    10400.0    3 years     2015      major_purchase         PA  25.37   \n",
       "5    11950.0    4 years     2015  debt_consolidation         GA  10.20   \n",
       "\n",
       "   fico_score  Class  \n",
       "0       677.0      0  \n",
       "1       717.0      0  \n",
       "2       697.0      0  \n",
       "4       697.0      0  \n",
       "5       692.0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_accepted = loans_accepted.loc[loans_accepted['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
    "loans_accepted['fico_score'] = 0.5*loans_accepted['fico_range_low'] + 0.5*loans_accepted['fico_range_high']\n",
    "loans_accepted.drop(['fico_range_high', 'fico_range_low'], axis=1, inplace=True)\n",
    "keep_list = [ 'loan_amnt','issue_d','purpose','fico_score','dti','emp_length','addr_state','emp_length','loan_status']\n",
    "drop_list = [col for col in loans_accepted.columns if col not in keep_list]\n",
    "loans_accepted.drop(labels=drop_list, axis=1, inplace=True)\n",
    "loans_accepted['Class'] = (loans_accepted['loan_status'] == 'Charged Off').apply(np.uint8)\n",
    "loans_accepted.drop('loan_status', axis=1, inplace=True)\n",
    "loans_accepted['emp_length']=loans_accepted['emp_length'].replace({'< 1 year': 'les1year'})\n",
    "loans_accepted['issue_d'] = loans_accepted['issue_d'].str.extract(r'-(\\d{4})').astype(int)\n",
    "loans_accepted=loans_accepted.dropna()\n",
    "loans_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c5d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_rejected=df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f919726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>4 years</td>\n",
       "      <td>2007</td>\n",
       "      <td>other</td>\n",
       "      <td>NJ</td>\n",
       "      <td>17.81</td>\n",
       "      <td>628.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>2007</td>\n",
       "      <td>other</td>\n",
       "      <td>NJ</td>\n",
       "      <td>35.13</td>\n",
       "      <td>674.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>2007</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>FL</td>\n",
       "      <td>36.92</td>\n",
       "      <td>710.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>2007</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>63.88</td>\n",
       "      <td>631.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>6 years</td>\n",
       "      <td>2007</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>MA</td>\n",
       "      <td>30.53</td>\n",
       "      <td>696.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loan_amnt emp_length  issue_d             purpose addr_state    dti  \\\n",
       "3015     5000.0    4 years     2007               other         NJ  17.81   \n",
       "3016     6000.0    8 years     2007               other         NJ  35.13   \n",
       "3017    20000.0    8 years     2007  debt_consolidation         FL  36.92   \n",
       "3018    10000.0  10+ years     2007  debt_consolidation         NY  63.88   \n",
       "3020     2000.0    6 years     2007  debt_consolidation         MA  30.53   \n",
       "\n",
       "      fico_score  Class  \n",
       "3015       628.0     -1  \n",
       "3016       674.0     -1  \n",
       "3017       710.0     -1  \n",
       "3018       631.0     -1  \n",
       "3020       696.0     -1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_rejected.drop(labels=['Zip Code','Policy Code'], axis=1, inplace=True)\n",
    "loans_rejected.columns = ['loan_amnt', 'issue_d','purpose','fico_score','dti','addr_state','emp_length']\n",
    "loans_rejected=loans_rejected.dropna()\n",
    "loans_rejected['dti'] = list(map(lambda x: x[:-1], loans_rejected['dti'].values))\n",
    "loans_rejected['dti'] = [float(x) for x in loans_rejected['dti'].values]\n",
    "loans_rejected['Class']=-1\n",
    "loans_rejected = loans_rejected[['loan_amnt','emp_length', 'issue_d','purpose','addr_state','dti','fico_score','Class']]\n",
    "options=['debt_consolidation','credit_card','home_improvement','house','medical','other','car','major_purchase'\n",
    ",'moving','small_business','vacation','renewable_energy','wedding','educational']\n",
    "loans_rejected = loans_rejected[loans_rejected['purpose'].isin(options)]\n",
    "loans_rejected['issue_d'] = pd.to_datetime(loans_rejected['issue_d']).dt.year\n",
    "loans_rejected = loans_rejected.drop(loans_rejected[loans_rejected.dti > 999].index)\n",
    "loans_rejected = loans_rejected.drop(loans_rejected[loans_rejected.loan_amnt > 40000].index)\n",
    "loans_rejected = loans_rejected.drop(loans_rejected[loans_rejected.fico_score < 627].index) \n",
    "loans_rejected['emp_length']=loans_rejected['emp_length'].replace({'< 1 year': 'les1year'})\n",
    "loans_rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240e89f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_amnt  issue_d addr_state    dti  fico_score  Class  \\\n",
      "0     3600.0     2015         PA   5.91       677.0      0   \n",
      "1    24700.0     2015         SD  16.06       717.0      0   \n",
      "2    20000.0     2015         IL  10.78       697.0      0   \n",
      "4    10400.0     2015         PA  25.37       697.0      0   \n",
      "5    11950.0     2015         GA  10.20       692.0      0   \n",
      "\n",
      "   emp_length_encoded  purpose_encoded  \n",
      "0                   1                2  \n",
      "1                   1               11  \n",
      "2                   1                4  \n",
      "4                   3                6  \n",
      "5                   4                2  \n",
      "      loan_amnt  issue_d addr_state    dti  fico_score  Class  \\\n",
      "3015     5000.0     2007         NJ  17.81       628.0     -1   \n",
      "3016     6000.0     2007         NJ  35.13       674.0     -1   \n",
      "3017    20000.0     2007         FL  36.92       710.0     -1   \n",
      "3018    10000.0     2007         NY  63.88       631.0     -1   \n",
      "3020     2000.0     2007         MA  30.53       696.0     -1   \n",
      "\n",
      "      emp_length_encoded  purpose_encoded  \n",
      "3015                   4                9  \n",
      "3016                   8                9  \n",
      "3017                   8                2  \n",
      "3018                   1                2  \n",
      "3020                   6                2  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoders\n",
    "le_emp_length = LabelEncoder()\n",
    "le_purpose = LabelEncoder()\n",
    "le_addr=LabelEncoder()\n",
    "# Fit on loans_accepted\n",
    "le_emp_length.fit(loans_accepted['emp_length'])\n",
    "le_purpose.fit(loans_accepted['purpose'])\n",
    "#le_addr.fit(loans_accepted['addr_state'])\n",
    "# Transform both datasets\n",
    "loans_accepted['emp_length_encoded'] = le_emp_length.transform(loans_accepted['emp_length'])\n",
    "loans_accepted['purpose_encoded'] = le_purpose.transform(loans_accepted['purpose'])\n",
    "#loans_accepted['addr_state_encoded']=le_addr.transform(loans_accepted['addr_state'])\n",
    "loans_rejected['emp_length_encoded'] = le_emp_length.transform(loans_rejected['emp_length'])\n",
    "loans_rejected['purpose_encoded'] = le_purpose.transform(loans_rejected['purpose'])\n",
    "#loans_rejected['addr_state_encoded']=le_addr.transform(loans_rejected['addr_state'])\n",
    "# Drop original categorical columns (optional)\n",
    "loans_accepted.drop(columns=['emp_length', 'purpose'], inplace=True)\n",
    "loans_rejected.drop(columns=['emp_length', 'purpose'], inplace=True)\n",
    "\n",
    "# Display result\n",
    "print(loans_accepted.head())\n",
    "print(loans_rejected.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5b3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Groupe 1 (Ã‰tats avec le plus de Class 0) :\n",
      " ['CA', 'TX', 'NY', 'FL', 'IL', 'NJ', 'PA', 'GA', 'OH', 'VA', 'NC', 'MI', 'AZ', 'MA', 'CO', 'MD', 'WA']\n",
      "\n",
      "ðŸ”¸ Groupe 2 (Ã‰tats intermÃ©diaires) :\n",
      " ['MN', 'IN', 'MO', 'CT', 'TN', 'NV', 'WI', 'OR', 'SC', 'AL', 'LA', 'KY', 'KS', 'OK', 'UT', 'AR', 'NM']\n",
      "\n",
      "âš« Groupe 3 (Ã‰tats avec le moins de Class 0) :\n",
      " ['NH', 'HI', 'RI', 'MS', 'WV', 'MT', 'DC', 'DE', 'NE', 'AK', 'WY', 'VT', 'SD', 'ME', 'ID', 'ND', 'IA']\n"
     ]
    }
   ],
   "source": [
    "# Filtrer uniquement les prÃªts oÃ¹ Class == 0\n",
    "class_0_counts = loans_accepted[loans_accepted['Class'] == 0]['addr_state'].value_counts()\n",
    "\n",
    "# Trier les Ã‰tats par nombre de prÃªts Class == 0 en ordre dÃ©croissant\n",
    "class_0_counts_sorted = class_0_counts.sort_values(ascending=False)\n",
    "\n",
    "# Diviser les Ã‰tats en 3 groupes de taille Ã©gale\n",
    "n = len(class_0_counts_sorted)\n",
    "group_1 = class_0_counts_sorted[:n//3].index.tolist()  # Top 1/3\n",
    "group_2 = class_0_counts_sorted[n//3:2*n//3].index.tolist()  # Milieu 1/3\n",
    "group_3 = class_0_counts_sorted[2*n//3:].index.tolist()  # Dernier 1/3\n",
    "\n",
    "# Afficher les groupes\n",
    "print(\"ðŸ”¹ Groupe 1 (Ã‰tats avec le plus de Class 0) :\\n\", group_1)\n",
    "print(\"\\nðŸ”¸ Groupe 2 (Ã‰tats intermÃ©diaires) :\\n\", group_2)\n",
    "print(\"\\nâš« Groupe 3 (Ã‰tats avec le moins de Class 0) :\\n\", group_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426e0237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  addr_state  d1  d2  d3\n",
      "0         PA   1   0   0\n",
      "1         SD   0   0   1\n",
      "2         IL   1   0   0\n",
      "4         PA   1   0   0\n",
      "5         GA   1   0   0\n",
      "     addr_state  d1  d2  d3\n",
      "3015         NJ   1   0   0\n",
      "3016         NJ   1   0   0\n",
      "3017         FL   1   0   0\n",
      "3018         NY   1   0   0\n",
      "3020         MA   1   0   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filtrer uniquement les prÃªts oÃ¹ Class == 0\n",
    "class_0_counts = loans_accepted[loans_accepted['Class'] == 0]['addr_state'].value_counts()\n",
    "\n",
    "# Trier les Ã‰tats par nombre de prÃªts Class == 0 en ordre dÃ©croissant\n",
    "class_0_counts_sorted = class_0_counts.sort_values(ascending=False)\n",
    "\n",
    "# Diviser les Ã‰tats en 3 groupes de taille Ã©gale\n",
    "n = len(class_0_counts_sorted)\n",
    "group_1 = class_0_counts_sorted[:n//3].index.tolist()  # Top 1/3\n",
    "group_2 = class_0_counts_sorted[n//3:2*n//3].index.tolist()  # Milieu 1/3\n",
    "group_3 = class_0_counts_sorted[2*n//3:].index.tolist()  # Dernier 1/3\n",
    "\n",
    "# Fonction pour attribuer les variables binaires\n",
    "def assign_groups(df):\n",
    "    df['d1'] = df['addr_state'].apply(lambda x: 1 if x in group_1 else 0)\n",
    "    df['d2'] = df['addr_state'].apply(lambda x: 1 if x in group_2 else 0)\n",
    "    df['d3'] = df['addr_state'].apply(lambda x: 1 if x in group_3 else 0)\n",
    "    return df\n",
    "\n",
    "# Appliquer aux deux datasets\n",
    "loans_accepted = assign_groups(loans_accepted)\n",
    "loans_rejected = assign_groups(loans_rejected)\n",
    "\n",
    "# VÃ©rification\n",
    "print(loans_accepted[['addr_state', 'd1', 'd2', 'd3']].head())\n",
    "print(loans_rejected[['addr_state', 'd1', 'd2', 'd3']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8d027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>Class</th>\n",
       "      <th>emp_length_encoded</th>\n",
       "      <th>purpose_encoded</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>PA</td>\n",
       "      <td>5.91</td>\n",
       "      <td>677.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>SD</td>\n",
       "      <td>16.06</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>IL</td>\n",
       "      <td>10.78</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>PA</td>\n",
       "      <td>25.37</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>GA</td>\n",
       "      <td>10.20</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  issue_d addr_state    dti  fico_score  Class  \\\n",
       "0     3600.0     2015         PA   5.91       677.0      0   \n",
       "1    24700.0     2015         SD  16.06       717.0      0   \n",
       "2    20000.0     2015         IL  10.78       697.0      0   \n",
       "4    10400.0     2015         PA  25.37       697.0      0   \n",
       "5    11950.0     2015         GA  10.20       692.0      0   \n",
       "\n",
       "   emp_length_encoded  purpose_encoded  d1  d2  d3  \n",
       "0                   1                2   1   0   0  \n",
       "1                   1               11   0   0   1  \n",
       "2                   1                4   1   0   0  \n",
       "4                   3                6   1   0   0  \n",
       "5                   4                2   1   0   0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31a8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_data=loans_accepted.drop(['Class','addr_state','issue_d'],axis=1)\n",
    "rejected_data=loans_rejected.drop(['Class','addr_state','issue_d'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d872ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common features: 8\n",
      "Common features: ['d2', 'd3', 'd1', 'emp_length_encoded', 'loan_amnt', 'fico_score', 'purpose_encoded', 'dti']\n"
     ]
    }
   ],
   "source": [
    "# Get the common features (columns) between the two datasets\n",
    "common_features = list(set(accepted_data.columns).intersection(set(rejected_data.columns)))\n",
    "\n",
    "print(\"Number of common features:\", len(common_features))\n",
    "print(\"Common features:\", common_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4176513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rejection labels\n",
    "accepted_data['rejected'] = 0\n",
    "rejected_data['rejected'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de0f0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([\n",
    "accepted_data[common_features + ['rejected']],\n",
    "rejected_data[common_features + ['rejected']]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cae685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X1 = combined_data.copy()\n",
    "y = X1['rejected']\n",
    "X=X1.drop('rejected',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e44e0494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d1</th>\n",
       "      <th>emp_length_encoded</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>purpose_encoded</th>\n",
       "      <th>dti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>11</td>\n",
       "      <td>16.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>6</td>\n",
       "      <td>25.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11950.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d2  d3  d1  emp_length_encoded  loan_amnt  fico_score  purpose_encoded  \\\n",
       "0   0   0   1                   1     3600.0       677.0                2   \n",
       "1   0   1   0                   1    24700.0       717.0               11   \n",
       "2   0   0   1                   1    20000.0       697.0                4   \n",
       "4   0   0   1                   3    10400.0       697.0                6   \n",
       "5   0   0   1                   4    11950.0       692.0                2   \n",
       "\n",
       "     dti  \n",
       "0   5.91  \n",
       "1  16.06  \n",
       "2  10.78  \n",
       "4  25.37  \n",
       "5  10.20  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bbb2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rejected\n",
       "1    0.61971\n",
       "0    0.38029\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8e17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppose X is a DataFrame\n",
    "float_cols = X.select_dtypes(include=['float64', 'float32']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "\n",
    "X_scaled[float_cols] = scaler.fit_transform(X[float_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d13bc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d1</th>\n",
       "      <th>emp_length_encoded</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>purpose_encoded</th>\n",
       "      <th>dti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.136930</td>\n",
       "      <td>-0.199229</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.525118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959310</td>\n",
       "      <td>0.876341</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.271477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.492375</td>\n",
       "      <td>0.338556</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.403420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.461364</td>\n",
       "      <td>0.338556</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.038827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.307375</td>\n",
       "      <td>0.204110</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.417914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d2  d3  d1  emp_length_encoded  loan_amnt  fico_score  purpose_encoded  \\\n",
       "0   0   0   1                   1  -1.136930   -0.199229                2   \n",
       "1   0   1   0                   1   0.959310    0.876341               11   \n",
       "2   0   0   1                   1   0.492375    0.338556                4   \n",
       "4   0   0   1                   3  -0.461364    0.338556                6   \n",
       "5   0   0   1                   4  -0.307375    0.204110                2   \n",
       "\n",
       "        dti  \n",
       "0 -0.525118  \n",
       "1 -0.271477  \n",
       "2 -0.403420  \n",
       "4 -0.038827  \n",
       "5 -0.417914  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed472e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit logistic regression to predict rejection\n",
    "mar_model = LogisticRegression(max_iter=1000,solver='liblinear',class_weight='balanced')\n",
    "mar_model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f0379dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC with confidence intervals using bootstrap\n",
    "n_bootstraps = 1000\n",
    "rng_seed = 42\n",
    "bootstrapped_scores = []\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    indices = rng.randint(0, len(X_scaled), len(X_scaled))\n",
    "\n",
    "    # Skip if only one class present\n",
    "    if len(np.unique(y.iloc[indices])) < 2:\n",
    "        continue\n",
    "\n",
    "    pred_proba = mar_model.predict_proba(X_scaled.iloc[indices])[:, 1]\n",
    "    score = roc_auc_score(y.iloc[indices], pred_proba)\n",
    "    bootstrapped_scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66990588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.939 (95% CI: 0.939-0.940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate confidence interval\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "ci_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "ci_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "print(f\"AUC: {np.mean(bootstrapped_scores):.3f} (95% CI: {ci_lower:.3f}-{ci_upper:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a32a36d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Fit logistic regression\u001b[39;00m\n\u001b[32m     15\u001b[39m model_temp = LogisticRegression(random_state=\u001b[32m42\u001b[39m, max_iter=\u001b[32m1000\u001b[39m,solver=\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m,class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mmodel_temp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Store coefficients\u001b[39;00m\n\u001b[32m     19\u001b[39m coefficients.append(model_temp.coef_[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m.n_jobs) != \u001b[32m1\u001b[39m:\n\u001b[32m   1216\u001b[39m         warnings.warn(\n\u001b[32m   1217\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mn_jobs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m > 1 does not have any effect when\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1218\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is set to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Got \u001b[39m\u001b[33m'\u001b[39m\u001b[33mn_jobs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1219\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(effective_n_jobs(\u001b[38;5;28mself\u001b[39m.n_jobs))\n\u001b[32m   1220\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     \u001b[38;5;28mself\u001b[39m.coef_, \u001b[38;5;28mself\u001b[39m.intercept_, \u001b[38;5;28mself\u001b[39m.n_iter_ = \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33msag\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1217\u001b[39m, in \u001b[36m_fit_liblinear\u001b[39m\u001b[34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[39m\n\u001b[32m   1214\u001b[39m sample_weight = _check_sample_weight(sample_weight, X, dtype=np.float64)\n\u001b[32m   1216\u001b[39m solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[32m-> \u001b[39m\u001b[32m1217\u001b[39m raw_coef_, n_iter_ = \u001b[43mliblinear\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[32m   1233\u001b[39m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[32m   1234\u001b[39m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[32m   1235\u001b[39m n_iter_max = \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "n_iterations = 1000\n",
    "coefficients = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Bootstrap sample\n",
    "    X_sample, y_sample = resample(X_scaled, y, random_state=None)\n",
    "    \n",
    "    # Fit logistic regression\n",
    "    model_temp = LogisticRegression(random_state=42, max_iter=1000,solver='liblinear',class_weight='balanced')\n",
    "    model_temp.fit(X_sample, y_sample)\n",
    "    \n",
    "    # Store coefficients\n",
    "    coefficients.append(model_temp.coef_[0])\n",
    "\n",
    "coefficients = np.array(coefficients)\n",
    "\n",
    "# Calculate mean and std of coefficients\n",
    "coef_mean = np.mean(coefficients, axis=0)\n",
    "coef_std = np.std(coefficients, axis=0)\n",
    "\n",
    "# Calculate z-scores and p-values\n",
    "z_scores = coef_mean / coef_std\n",
    "p_values = 2 * (1 - stats.norm.cdf(np.abs(z_scores)))\n",
    "\n",
    "# Create results table\n",
    "results_df = pd.DataFrame({\n",
    "    'Feature': common_features,\n",
    "    'Coefficient': coef_mean,\n",
    "    'Std Error': coef_std,\n",
    "    'p-value': p_values\n",
    "})\n",
    "\n",
    "print(\"\\nCoefficients Table:\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b79d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hosmer-Lemeshow Test:\n",
      "Chi-square statistic: 96131.647\n",
      "p-value: 0.00000000000000000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Compute predicted probabilities using cross-validation\n",
    "y_pred_proba = cross_val_predict(\n",
    "    mar_model, X_scaled, y, cv=5, method='predict_proba'\n",
    ")[:, 1]\n",
    "\n",
    "# Number of bins for HL test\n",
    "n_bins = 10\n",
    "\n",
    "# Define bin edges by percentiles\n",
    "bin_edges = np.percentile(y_pred_proba, np.linspace(0, 100, n_bins + 1))\n",
    "\n",
    "# Assign each observation to a bin\n",
    "bin_indices = np.digitize(y_pred_proba, bin_edges, right=True) - 1\n",
    "bin_indices[bin_indices == n_bins] = n_bins - 1  # edge case for max value\n",
    "\n",
    "observed = []\n",
    "expected = []\n",
    "\n",
    "for i in range(n_bins):\n",
    "    mask = bin_indices == i\n",
    "    observed.append(np.sum(y[mask]))\n",
    "    expected.append(np.sum(y_pred_proba[mask]))\n",
    "\n",
    "observed = np.array(observed)\n",
    "expected = np.array(expected)\n",
    "\n",
    "# Hosmer-Lemeshow test statistic\n",
    "chi2_stat = np.sum((observed - expected) ** 2 / expected)\n",
    "p_value_hl = 1 - stats.chi2.cdf(chi2_stat, df=n_bins - 2)\n",
    "\n",
    "print(\"\\nHosmer-Lemeshow Test:\")\n",
    "print(f\"Chi-square statistic: {chi2_stat:.3f}\")\n",
    "print(f\"p-value: {p_value_hl:.20f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d14db06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "class LogisticCEMD2(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A semi-supervised learning classifier using a Classification-Expectation-Maximization (CEM)\n",
    "    approach with a Logistic Regression base model.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=200, epsilon=1e-5, degree=2, lambda_=1.0,\n",
    "                 interactions_only=False, random_state=42,\n",
    "                 early_stopping=True, patience=3, n_jobs=-1, solver='liblinear'):\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.epsilon = epsilon\n",
    "        self.degree = degree\n",
    "        self.lambda_ = lambda_\n",
    "        self.interactions_only = interactions_only\n",
    "        self.random_state = random_state\n",
    "        self.early_stopping = early_stopping\n",
    "        self.patience = patience\n",
    "        self.n_jobs = n_jobs\n",
    "        self.solver = solver\n",
    "        self.poly = None\n",
    "        self.scaler = None\n",
    "        self.G = None\n",
    "        self.history = {'log_likelihood': []}\n",
    "\n",
    "    def _apply_polynomial_features(self, X):\n",
    "        \"\"\"Applies polynomial feature transformation and scaling.\"\"\"\n",
    "        if self.poly is None:\n",
    "            self.poly = PolynomialFeatures(degree=self.degree,\n",
    "                                           include_bias=False,\n",
    "                                           interaction_only=self.interactions_only)\n",
    "            self.poly.fit(X)\n",
    "\n",
    "        X_poly = self.poly.transform(X)\n",
    "\n",
    "        if self.scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(X_poly)\n",
    "            \n",
    "        return self.scaler.transform(X_poly)\n",
    "\n",
    "    def fit(self, X_l, y_l, X_u, init_unlabeled_labels=None, return_history=False):\n",
    "        \"\"\"\n",
    "        Trains the Logistic-CEM-D2 model.\n",
    "        \n",
    "        Parameters:\n",
    "        - X_l: Labeled feature matrix.\n",
    "        - y_l: Labeled target vector.\n",
    "        - X_u: Unlabeled feature matrix.\n",
    "        - init_unlabeled_labels: Optional initial labels for X_u.\n",
    "        - return_history: If True, returns the log-likelihood history.\n",
    "        \"\"\"\n",
    "        # --- Initialization Step ---\n",
    "        X_l_poly = self._apply_polynomial_features(X_l)\n",
    "        X_u_poly = self._apply_polynomial_features(X_u)\n",
    "        \n",
    "        # Initial fit on labeled data\n",
    "        # Use C = 1/lambda as per scikit-learn's convention\n",
    "        self.G = LogisticRegression(\n",
    "            C=1.0 / self.lambda_,  \n",
    "            penalty='l1',  \n",
    "            solver=self.solver,\n",
    "            max_iter=5000,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=self.n_jobs\n",
    "        )\n",
    "        self.G.fit(X_l_poly, y_l)\n",
    "\n",
    "        # Handle optional initial labels for unlabeled data\n",
    "        if init_unlabeled_labels is not None:\n",
    "            z_ki = init_unlabeled_labels\n",
    "        else:\n",
    "            z_ki = self.G.predict(X_u_poly)\n",
    "            \n",
    "        prev_log_likelihood = -np.inf\n",
    "        no_improvement_count = 0\n",
    "\n",
    "        # --- CEM Loop ---\n",
    "        for j in range(self.max_iter):\n",
    "            # E-Step: Estimate posterior probabilities for unlabeled data\n",
    "            probas_u = self.G.predict_proba(X_u_poly)\n",
    "            \n",
    "            # C-Step: Hard assignment based on max posterior\n",
    "            z_ki = (probas_u[:, 1] > 0.5).astype(int)\n",
    "            \n",
    "            # M-Step: Maximize complete-data log-likelihood\n",
    "            X_combined = np.vstack([X_l_poly, X_u_poly])\n",
    "            y_combined = np.hstack([y_l, z_ki])\n",
    "\n",
    "            self.G.fit(X_combined, y_combined)\n",
    "            \n",
    "            current_log_likelihood = self._log_likelihood(X_l_poly, y_l, X_u_poly, z_ki)\n",
    "            self.history['log_likelihood'].append(current_log_likelihood)\n",
    "\n",
    "            # Early stopping check\n",
    "            improvement = current_log_likelihood - prev_log_likelihood\n",
    "            if improvement < self.epsilon:\n",
    "                no_improvement_count += 1\n",
    "                if self.early_stopping and no_improvement_count >= self.patience:\n",
    "                    break\n",
    "            else:\n",
    "                no_improvement_count = 0\n",
    "            \n",
    "            prev_log_likelihood = current_log_likelihood\n",
    "        \n",
    "        if return_history:\n",
    "            return self.history\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predicts labels for new data.\"\"\"\n",
    "        X_test_poly = self._apply_polynomial_features(X_test)\n",
    "        return self.G.predict(X_test_poly)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        \"\"\"Predicts class probabilities for new data.\"\"\"\n",
    "        X_test_poly = self._apply_polynomial_features(X_test)\n",
    "        return self.G.predict_proba(X_test_poly)\n",
    "        \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        return self.G.coef_\n",
    "        \n",
    "    @property\n",
    "    def intercept_(self):\n",
    "        return self.G.intercept_\n",
    "\n",
    "    def _log_likelihood(self, X_l, y_l, X_u, z_ki):\n",
    "        \"\"\"Calculates the complete-data log-likelihood with L1 regularization.\"\"\"\n",
    "        X_combined = np.vstack([X_l, X_u])\n",
    "        y_combined = np.hstack([y_l, z_ki])\n",
    "        \n",
    "        linear_output = X_combined @ self.G.coef_.T + self.G.intercept_\n",
    "        probas = 1 / (1 + np.exp(-linear_output))\n",
    "        \n",
    "        epsilon = 1e-9\n",
    "        log_likelihood = np.sum(y_combined * np.log(probas + epsilon) + \n",
    "                                (1 - y_combined) * np.log(1 - probas + epsilon))\n",
    "        \n",
    "        # Add the L1 regularization penalty\n",
    "        l1_penalty = self.lambda_ * np.sum(np.abs(self.G.coef_))\n",
    "        log_likelihood -= l1_penalty\n",
    "        \n",
    "        return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad60ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "class LogisticCEM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, epsilon=1e-4):\n",
    "        self.epsilon = epsilon\n",
    "        self.model = LogisticRegression(solver='saga')\n",
    "        self.is_fitted_ = False\n",
    "\n",
    "    def _log_likelihood(self, beta, X, y):\n",
    "        X_beta = np.dot(X, beta)\n",
    "        log_probs = -log_loss(y, sigmoid(X_beta), labels=[0, 1], normalize=False)\n",
    "        return log_probs\n",
    "\n",
    "    def fit(self, X_l, y_l, X_u=None):\n",
    "        if X_u is None:\n",
    "            raise ValueError(\"Unlabeled data X_u must be provided for CEM.\")\n",
    "\n",
    "        # Initial supervised fit\n",
    "        self.model.fit(X_l, y_l)\n",
    "        prob_u = self.model.predict_proba(X_u)\n",
    "        P = np.argmax(prob_u, axis=1)\n",
    "\n",
    "        # Combine data\n",
    "        X_combined = np.vstack((X_l, X_u))\n",
    "        y_combined = np.hstack((y_l, P))\n",
    "\n",
    "        X_with_intercept = np.hstack([np.ones((X_combined.shape[0], 1)), X_combined])\n",
    "        beta = np.hstack([self.model.intercept_, self.model.coef_.ravel()])\n",
    "        prev_ll = self._log_likelihood(beta, X_with_intercept, y_combined)\n",
    "        delta_ll = np.inf\n",
    "\n",
    "        while delta_ll > self.epsilon:\n",
    "            # E-step\n",
    "            prob_u = self.model.predict_proba(X_u)\n",
    "            P = np.argmax(prob_u, axis=1)\n",
    "            y_combined[len(y_l):] = P\n",
    "\n",
    "            # M-step\n",
    "            result = minimize(lambda b: -self._log_likelihood(b, X_with_intercept, y_combined), \n",
    "                              beta, method='BFGS')\n",
    "            beta_new = result.x\n",
    "            new_ll = self._log_likelihood(beta_new, X_with_intercept, y_combined)\n",
    "            delta_ll = abs(new_ll - prev_ll)\n",
    "\n",
    "            # Update model\n",
    "            self.model.intercept_ = np.array([beta_new[0]])\n",
    "            self.model.coef_ = beta_new[1:].reshape(1, -1)\n",
    "            beta = beta_new\n",
    "            prev_ll = new_ll\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted_:\n",
    "            raise RuntimeError(\"You must call fit() before predict().\")\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self.is_fitted_:\n",
    "            raise RuntimeError(\"You must call fit() before predict_proba().\")\n",
    "        return self.model.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2b0d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_rejected.drop(['addr_state','issue_d','Class'],axis=1,inplace=True )\n",
    "loans_accepted.drop(['addr_state','issue_d'],axis=1,inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dabc66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Ã‰chantillonnage des donnÃ©es\n",
    "# -------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample 25,000 rejected loans (if needed, not yet used here)\n",
    "X_unlabeled = loans_rejected.sample(25000)\n",
    "\n",
    "# Separate accepted loans by class\n",
    "class_0 = loans_accepted[loans_accepted[\"Class\"] == 0]\n",
    "class_1 = loans_accepted[loans_accepted[\"Class\"] == 1]\n",
    "\n",
    "# Determine balanced sample size\n",
    "a=1000\n",
    "#a = min(class_0.shape[0], class_1.shape[0])\n",
    "\n",
    "# Sample equal number of instances from each class\n",
    "class_0_sample = class_0.sample(n=a, random_state=42)\n",
    "class_1_sample = class_1.sample(n=a, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "loans_accepted_balanced = pd.concat([class_0_sample, class_1_sample]) \\\n",
    "                            .sample(frac=1, random_state=42) \\\n",
    "                            .reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Split into training and test sets\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    loans_accepted_balanced.drop(columns=[\"Class\"]),\n",
    "    loans_accepted_balanced[\"Class\"],\n",
    "    test_size=0.2,\n",
    "    stratify=loans_accepted_balanced[\"Class\"],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33521b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>Class</th>\n",
       "      <th>emp_length_encoded</th>\n",
       "      <th>purpose_encoded</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>677.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>16.06</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>25.37</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>10.20</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt    dti  fico_score  Class  emp_length_encoded  purpose_encoded  \\\n",
       "0     3600.0   5.91       677.0      0                   1                2   \n",
       "1    24700.0  16.06       717.0      0                   1               11   \n",
       "2    20000.0  10.78       697.0      0                   1                4   \n",
       "4    10400.0  25.37       697.0      0                   3                6   \n",
       "5    11950.0  10.20       692.0      0                   4                2   \n",
       "\n",
       "   d1  d2  d3  \n",
       "0   1   0   0  \n",
       "1   0   0   1  \n",
       "2   1   0   0  \n",
       "4   1   0   0  \n",
       "5   1   0   0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb7a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60bf2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "968dcd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "del loans_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a7d75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del loans_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07dc1d9",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization and sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0bf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Starting grid search and cross-validation...\n",
      "  > Testing lambda = 0.001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define parameters for grid search\n",
    "lambda_grid = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv_folds = 5\n",
    "random_state = 42\n",
    "cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "# --- 2. Perform Grid Search with Correct Slicing ---\n",
    "print(\"\\nðŸ” Starting grid search and cross-validation...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for lambda_val in lambda_grid:\n",
    "    print(f\"  > Testing lambda = {lambda_val}\")\n",
    "    \n",
    "    fold_train_aucs = []\n",
    "    fold_val_aucs = []\n",
    "    fold_feature_counts = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        # Use .iloc for slicing pandas DataFrames\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model = LogisticCEMD2(lambda_=lambda_val, max_iter=50, random_state=random_state)\n",
    "        \n",
    "        # CORRECTED LINE: Pass X_unlabeled as a positional argument\n",
    "        model.fit(X_tr.values, y_tr.values, X_unlabeled)\n",
    "        \n",
    "        # Calculate AUC metrics\n",
    "        train_pred_proba = model.predict_proba(X_tr.values)[:, 1]\n",
    "        val_pred_proba = model.predict_proba(X_val.values)[:, 1]\n",
    "        \n",
    "        fold_train_aucs.append(roc_auc_score(y_tr.values, train_pred_proba))\n",
    "        fold_val_aucs.append(roc_auc_score(y_val.values, val_pred_proba))\n",
    "        \n",
    "        # Count non-zero features\n",
    "        nonzero_features = np.sum(np.abs(model.coef_) > 1e-6)\n",
    "        fold_feature_counts.append(nonzero_features)\n",
    "    \n",
    "    # Store aggregated results\n",
    "    results.append({\n",
    "        'lambda': lambda_val,\n",
    "        'train_auc': np.mean(fold_train_aucs),\n",
    "        'val_auc': np.mean(fold_val_aucs),\n",
    "        'n_features': np.mean(fold_feature_counts),\n",
    "        'overfitting_metric': np.mean(fold_train_aucs) - np.mean(fold_val_aucs)\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing and plotting\n",
    "results_df = pd.DataFrame(results).sort_values(by='lambda')\n",
    "print(\"\\nðŸ“Š Grid Search Results:\")\n",
    "print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "# --- 3. Visualize the Results (Validation Curves) ---\n",
    "def plot_validation_curves(df):\n",
    "    \"\"\"Generates and saves plots showing model performance vs. lambda.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot 1: AUC vs Lambda\n",
    "    axes[0].semilogx(df['lambda'], df['train_auc'], 'b-', marker='o', label='Train AUC')\n",
    "    axes[0].semilogx(df['lambda'], df['val_auc'], 'r-', marker='o', label='Validation AUC')\n",
    "    axes[0].set_xlabel('Lambda (log scale)')\n",
    "    axes[0].set_ylabel('AUC Score')\n",
    "    axes[0].set_title('AUC vs. Regularization Parameter (Grid Search)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Feature Count vs Lambda\n",
    "    axes[1].semilogx(df['lambda'], df['n_features'], 'g-', marker='o')\n",
    "    axes[1].set_xlabel('Lambda (log scale)')\n",
    "    axes[1].set_ylabel('Number of Features')\n",
    "    axes[1].set_title('Feature Selection vs. Lambda')\n",
    "    axes[1].grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Overfitting Metric vs Lambda\n",
    "    axes[2].semilogx(df['lambda'], df['overfitting_metric'], 'm-', marker='o')\n",
    "    axes[2].set_xlabel('Lambda (log scale)')\n",
    "    axes[2].set_ylabel('Train AUC - Validation AUC')\n",
    "    axes[2].set_title('Overfitting vs. Lambda')\n",
    "    axes[2].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[2].grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(\"Model Performance Analysis\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig('grid_search_curves.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_validation_curves(results_df)\n",
    "\n",
    "# --- 4. Sensitivity Analysis around Optimal Lambda ---\n",
    "# Find the lambda value that gave the highest validation AUC\n",
    "optimal_lambda = results_df.loc[results_df['val_auc'].idxmax(), 'lambda']\n",
    "print(f\"\\nðŸŽ‰ The optimal lambda found by grid search is: {optimal_lambda:.4f}\")\n",
    "\n",
    "# Define a range for sensitivity analysis\n",
    "sensitivity_range = np.linspace(optimal_lambda * 0.8, optimal_lambda * 1.2, 5)\n",
    "print(\"\\nðŸ”¬ Performing sensitivity analysis around the optimal lambda...\")\n",
    "\n",
    "sensitivity_results = []\n",
    "# Loop through a small range and run cross-validation multiple times\n",
    "for lambda_val in sensitivity_range:\n",
    "    aucs_for_lambda = []\n",
    "    \n",
    "    for seed in range(10): \n",
    "        cv_stability = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=seed)\n",
    "        model = LogisticCEMD2(lambda_=lambda_val, max_iter=50, random_state=seed)\n",
    "        \n",
    "        fold_scores = []\n",
    "        for train_idx, val_idx in cv_stability.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # CORRECTED LINE: Pass X_unlabeled as a positional argument\n",
    "            model.fit(X_tr.values, y_tr.values, X_unlabeled)\n",
    "            val_pred_proba = model.predict_proba(X_val.values)[:, 1]\n",
    "            fold_scores.append(roc_auc_score(y_val.values, val_pred_proba))\n",
    "            \n",
    "        aucs_for_lambda.append(np.mean(fold_scores))\n",
    "    \n",
    "    mean_auc = np.mean(aucs_for_lambda)\n",
    "    std_auc = np.std(aucs_for_lambda)\n",
    "    cv_auc = std_auc / mean_auc if mean_auc != 0 else 0\n",
    "\n",
    "    sensitivity_results.append({\n",
    "        'lambda': lambda_val,\n",
    "        'mean_auc': mean_auc,\n",
    "        'std_auc': std_auc,\n",
    "        'cv': cv_auc\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "print(\"\\nðŸ“ˆ Sensitivity Analysis Results:\")\n",
    "print(sensitivity_df.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\nâœ… Script execution completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112d638",
   "metadata": {},
   "source": [
    "### Initialization impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Starting experiments with 10 runs per method...\n",
      "\n",
      "> Testing Baseline initialization...\n",
      "\n",
      "> Testing Random initialization...\n",
      "\n",
      "> Testing K-means initialization...\n",
      "\n",
      "> Testing Semi-random initialization...\n",
      "\n",
      "> Testing Conservative initialization...\n",
      "\n",
      "ðŸ“Š Convergence and Performance by Initialization Method:\n",
      "      Method  Final_LL_Mean  Final_LL_Std  Iterations_Mean  Iterations_Std  Time_Mean  AUC_Mean  AUC_Std\n",
      "    Baseline  -1.719805e+06       91.4706              9.0             0.0     1.3815    0.6243   0.0003\n",
      "      Random  -1.719805e+06       91.4706              9.0             0.0     1.0122    0.6243   0.0003\n",
      "     K-means  -1.719805e+06       91.4706              9.0             0.0     1.1328    0.6243   0.0003\n",
      " Semi-random  -1.719805e+06       91.4706              9.0             0.0     1.0649    0.6243   0.0003\n",
      "Conservative  -1.719805e+06       91.4706              9.0             0.0     1.2367    0.6243   0.0003\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Analyzing convergence stability...\n",
      "  - Baseline: 100.0% of runs converged to a stable solution.\n",
      "  - Random: 100.0% of runs converged to a stable solution.\n",
      "  - K-means: 100.0% of runs converged to a stable solution.\n",
      "  - Semi-random: 100.0% of runs converged to a stable solution.\n",
      "  - Conservative: 100.0% of runs converged to a stable solution.\n",
      "\n",
      "âœ… Script execution completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "\n",
    "# --- 2. Define Initialization Methods ---\n",
    "def baseline_init(X_labeled, y_labeled, X_unlabeled):\n",
    "    \"\"\"Initializes using predictions from a regularized logistic regression on labeled data.\"\"\"\n",
    "    lr = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42)\n",
    "    lr.fit(X_labeled, y_labeled)\n",
    "    predictions = lr.predict(X_unlabeled)\n",
    "    return predictions\n",
    "\n",
    "def random_init(X_unlabeled):\n",
    "    \"\"\"Assigns labels to unlabeled points completely at random.\"\"\"\n",
    "    n_unlabeled = X_unlabeled.shape[0]\n",
    "    return np.random.randint(0, 2, n_unlabeled)\n",
    "\n",
    "def kmeans_init(X_labeled, X_unlabeled):\n",
    "    \"\"\"Clusters all data (labeled and unlabeled) and uses cluster assignments as initial labels.\"\"\"\n",
    "    X_all = np.vstack([X_labeled, X_unlabeled])\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10, init='k-means++')\n",
    "    kmeans.fit(X_all)\n",
    "    return kmeans.labels_[len(X_labeled):]\n",
    "\n",
    "def semi_random_init(X_labeled, y_labeled, X_unlabeled, perturb_ratio=0.2):\n",
    "    \"\"\"Initializes with baseline predictions, but flips a percentage of them randomly.\"\"\"\n",
    "    baseline_pred = baseline_init(X_labeled, y_labeled, X_unlabeled)\n",
    "    n_perturb = int(perturb_ratio * len(baseline_pred))\n",
    "    perturb_idx = np.random.choice(len(baseline_pred), n_perturb, replace=False)\n",
    "    baseline_pred[perturb_idx] = 1 - baseline_pred[perturb_idx]\n",
    "    return baseline_pred\n",
    "\n",
    "def conservative_init(y_labeled, X_unlabeled):\n",
    "    \"\"\"Assigns all unlabeled points to the majority class found in the labeled data.\"\"\"\n",
    "    majority_class = np.bincount(y_labeled).argmax()\n",
    "    return np.full(X_unlabeled.shape[0], majority_class)\n",
    "\n",
    "# Store initialization methods in a dictionary\n",
    "init_methods = {\n",
    "    'Baseline': lambda x_l, y_l, x_u: baseline_init(x_l, y_l, x_u),\n",
    "    'Random': lambda x_l, y_l, x_u: random_init(x_u),\n",
    "    'K-means': lambda x_l, y_l, x_u: kmeans_init(x_l, x_u),\n",
    "    'Semi-random': lambda x_l, y_l, x_u: semi_random_init(x_l, y_l, x_u),\n",
    "    'Conservative': lambda x_l, y_l, x_u: conservative_init(y_l, x_u)\n",
    "}\n",
    "\n",
    "# --- 3. Run Experiments ---\n",
    "n_runs = 10\n",
    "results = []\n",
    "convergence_histories = {}\n",
    "all_final_log_likelihoods = {method: [] for method in init_methods}\n",
    "\n",
    "print(f\"ðŸ”¬ Starting experiments with {n_runs} runs per method...\")\n",
    "\n",
    "for method_name, init_func in init_methods.items():\n",
    "    print(f\"\\n> Testing {method_name} initialization...\")\n",
    "    method_results = {\n",
    "        'log_likelihoods': [],\n",
    "        'iterations': [],\n",
    "        'times': [],\n",
    "        'aucs': []\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        run_random_state = 42 + run\n",
    "        np.random.seed(run_random_state) \n",
    "\n",
    "        init_labels = init_func(X_train, y_train, X_unlabeled)\n",
    "        \n",
    "        # Train model\n",
    "        model = LogisticCEMD2(max_iter=50, random_state=run_random_state)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # CORRECTED: Use 'X_u' keyword for the unlabeled data\n",
    "        history = model.fit(X_train, y_train, X_u=X_unlabeled, init_unlabeled_labels=init_labels, return_history=True)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        final_ll = history['log_likelihood'][-1]\n",
    "        method_results['log_likelihoods'].append(final_ll)\n",
    "        method_results['iterations'].append(len(history['log_likelihood']))\n",
    "        method_results['times'].append(end_time - start_time)\n",
    "        \n",
    "        test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        method_results['aucs'].append(test_auc)\n",
    "\n",
    "        if run == 0:\n",
    "            convergence_histories[method_name] = history['log_likelihood']\n",
    "        \n",
    "        all_final_log_likelihoods[method_name].append(final_ll)\n",
    "\n",
    "    results.append({\n",
    "        'Method': method_name,\n",
    "        'Final_LL_Mean': np.mean(method_results['log_likelihoods']),\n",
    "        'Final_LL_Std': np.std(method_results['log_likelihoods']),\n",
    "        'Iterations_Mean': np.mean(method_results['iterations']),\n",
    "        'Iterations_Std': np.std(method_results['iterations']),\n",
    "        'Time_Mean': np.mean(method_results['times']),\n",
    "        'AUC_Mean': np.mean(method_results['aucs']),\n",
    "        'AUC_Std': np.std(method_results['aucs'])\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nðŸ“Š Convergence and Performance by Initialization Method:\")\n",
    "print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "# --- 4. Visualize Convergence Curves ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "for method_name, history in convergence_histories.items():\n",
    "    plt.plot(history, label=method_name, linewidth=2)\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "plt.title('Convergence Behavior by Initialization Method (First Run)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('convergence_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 5. Analyze Convergence to a Stable Solution ---\n",
    "print(\"\\nðŸ” Analyzing convergence stability...\")\n",
    "for method_name, final_lls in all_final_log_likelihoods.items():\n",
    "    if not final_lls:\n",
    "        continue\n",
    "    \n",
    "    primary_ll = np.median(final_lls)\n",
    "    tolerance = 0.01 * np.abs(primary_ll)\n",
    "    similar_runs = np.sum(np.abs(np.array(final_lls) - primary_ll) < tolerance)\n",
    "    convergence_rate = (similar_runs / len(final_lls)) * 100\n",
    "    \n",
    "    print(f\"  - {method_name}: {convergence_rate:.1f}% of runs converged to a stable solution.\")\n",
    "\n",
    "print(\"\\nâœ… Script execution completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Error: Missing data file. Please check your file paths. Details: [Errno 2] No such file or directory: 'X_train_linear.npy'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base_estimator.predict_proba(X)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# --- 3. Define Configurations ---\u001b[39;00m\n\u001b[32m     94\u001b[39m configs = {\n\u001b[32m     95\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBase\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     96\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: LogisticRegression(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mX_train\u001b[49m,\n\u001b[32m     98\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     99\u001b[39m     },\n\u001b[32m    100\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBase + SSL\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    101\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: LogisticCEM(), \n\u001b[32m    102\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X_train,\n\u001b[32m    103\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: X_unlabeled\n\u001b[32m    104\u001b[39m     },\n\u001b[32m    105\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBase + Poly\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    106\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: LogisticRegression(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m    107\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X_train,\n\u001b[32m    108\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    109\u001b[39m     },\n\u001b[32m    110\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBase + Poly + L1\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    111\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: LogisticRegression(penalty=\u001b[33m'\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m'\u001b[39m, solver=\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m, C=\u001b[32m10\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m    112\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X_train,\n\u001b[32m    113\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    114\u001b[39m     },\n\u001b[32m    115\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBase + SSL + Poly\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    116\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: LogisticCEMD2(lambda_=\u001b[32m0\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m    117\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X_train,\n\u001b[32m    118\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: X_unlabeled\n\u001b[32m    119\u001b[39m     },\n\u001b[32m    120\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFull Model\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    121\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: LogisticCEMD2(lambda_=\u001b[32m0.1\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m    122\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X_train,\n\u001b[32m    123\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: X_unlabeled\n\u001b[32m    124\u001b[39m     },\n\u001b[32m    125\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSelf-Training\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m    126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: SelfTrainingClassifier(threshold=\u001b[32m0.8\u001b[39m, max_iter=\u001b[32m10\u001b[39m),\n\u001b[32m    127\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X_train,\n\u001b[32m    128\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mX_unlabeled\u001b[39m\u001b[33m'\u001b[39m: X_unlabeled\n\u001b[32m    129\u001b[39m     }\n\u001b[32m    130\u001b[39m }\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# --- 4. Run Ablation Study ---\u001b[39;00m\n\u001b[32m    133\u001b[39m n_runs = \u001b[32m25\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "import time\n",
    "\n",
    "# Assuming your implementations are correctly imported\n",
    "# from your_module import LogisticCEM, LogisticCEMD2\n",
    "\n",
    "# --- Placeholder Classes for Demonstration ---\n",
    "class LogisticCEM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression()\n",
    "    def fit(self, X_l, y_l, X_u):\n",
    "        self.model.fit(np.vstack((X_l, X_u)), np.hstack((y_l, np.zeros(X_u.shape[0]))))\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "class LogisticCEMD2(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, lambda_, random_state):\n",
    "        self.lambda_ = lambda_\n",
    "        self.random_state = random_state\n",
    "        self.model = LogisticRegression()\n",
    "    def fit(self, X_l, y_l, X_u):\n",
    "        self.model.fit(np.vstack((X_l, X_u)), np.hstack((y_l, np.zeros(X_u.shape[0]))))\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    # Now, explicitly load as a DataFrame or check if it's already a DataFrame\n",
    "    # Let's assume the user's data is an array but they are getting a KeyError\n",
    "    # because of a mixed-type variable. A common solution is to ensure everything\n",
    "    # is a NumPy array from the start.\n",
    "    X_train = np.load('X_train_linear.npy')\n",
    "    y_train = np.load('y_train.npy')\n",
    "    X_unlabeled = np.load('X_unlabeled_linear.npy')\n",
    "    \n",
    "    # Correcting for the Pandas KeyError: If X_train is a DataFrame, convert it.\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        X_train = X_train.values\n",
    "    if isinstance(X_unlabeled, pd.DataFrame):\n",
    "        X_unlabeled = X_unlabeled.values\n",
    "    \n",
    "    print(\"âœ… Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ðŸš¨ Error: Missing data file. Please check your file paths. Details: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Define Self-Training Baseline ---\n",
    "class SelfTrainingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator=None, threshold=0.75, max_iter=10):\n",
    "        self.base_estimator = base_estimator or LogisticRegression()\n",
    "        self.threshold = threshold\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X_labeled, y_labeled, X_unlabeled):\n",
    "        X_train_labeled = X_labeled.copy()\n",
    "        y_train_labeled = y_labeled.copy()\n",
    "        X_pool = X_unlabeled.copy()\n",
    "        for _ in range(self.max_iter):\n",
    "            self.base_estimator.fit(X_train_labeled, y_train_labeled)\n",
    "            if len(X_pool) == 0:\n",
    "                break\n",
    "            proba = self.base_estimator.predict_proba(X_pool)\n",
    "            max_proba = np.max(proba, axis=1)\n",
    "            high_conf_idx = max_proba >= self.threshold\n",
    "            if not np.any(high_conf_idx):\n",
    "                break\n",
    "            X_new = X_pool[high_conf_idx]\n",
    "            y_new = np.argmax(proba[high_conf_idx], axis=1)\n",
    "            X_train_labeled = np.vstack([X_train_labeled, X_new])\n",
    "            y_train_labeled = np.hstack([y_train_labeled, y_new])\n",
    "            X_pool = X_pool[~high_conf_idx]\n",
    "        self.base_estimator.fit(X_train_labeled, y_train_labeled)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.base_estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.base_estimator.predict_proba(X)\n",
    "\n",
    "# --- 3. Define Configurations ---\n",
    "configs = {\n",
    "    'Base': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'X': X_train,\n",
    "        'X_unlabeled': None\n",
    "    },\n",
    "    'Base + SSL': {\n",
    "        'model': LogisticCEM(), \n",
    "        'X': X_train,\n",
    "        'X_unlabeled': X_unlabeled\n",
    "    },\n",
    "    'Base + Poly': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'X': X_train,\n",
    "        'X_unlabeled': None\n",
    "    },\n",
    "    'Base + Poly + L1': {\n",
    "        'model': LogisticRegression(penalty='l1', solver='liblinear', C=10, random_state=42),\n",
    "        'X': X_train,\n",
    "        'X_unlabeled': None\n",
    "    },\n",
    "    'Base + SSL + Poly': {\n",
    "        'model': LogisticCEMD2(lambda_=0, random_state=42),\n",
    "        'X': X_train,\n",
    "        'X_unlabeled': X_unlabeled\n",
    "    },\n",
    "    'Full Model': {\n",
    "        'model': LogisticCEMD2(lambda_=0.1, random_state=42),\n",
    "        'X': X_train,\n",
    "        'X_unlabeled': X_unlabeled\n",
    "    },\n",
    "    'Self-Training': {\n",
    "        'model': SelfTrainingClassifier(threshold=0.8, max_iter=10),\n",
    "        'X': X_train,\n",
    "        'X_unlabeled': X_unlabeled\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- 4. Run Ablation Study ---\n",
    "n_runs = 25\n",
    "ablation_results = []\n",
    "all_scores = {}\n",
    "\n",
    "print(f\"ðŸ”¬ Starting ablation study with {n_runs} runs per configuration...\")\n",
    "\n",
    "for config_name, config in configs.items():\n",
    "    print(f\"\\n> Testing: {config_name}\")\n",
    "    start_time = time.time()\n",
    "    aucs = []\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        cv_run = StratifiedKFold(n_splits=5, shuffle=True, random_state=run)\n",
    "        run_aucs = []\n",
    "\n",
    "        # The fix is here: .iloc for Pandas DataFrames or ensuring NumPy arrays\n",
    "        # If your data is a DataFrame, use .iloc for integer indexing\n",
    "        if isinstance(config['X'], pd.DataFrame):\n",
    "            for train_idx, val_idx in cv_run.split(config['X'], y_train):\n",
    "                X_tr, X_val = config['X'].iloc[train_idx], config['X'].iloc[val_idx]\n",
    "                y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "                model = clone(config['model'])\n",
    "\n",
    "                if config['X_unlabeled'] is not None:\n",
    "                    model.fit(X_tr, y_tr, X_u=config['X_unlabeled'])\n",
    "                else:\n",
    "                    model.fit(X_tr, y_tr)\n",
    "\n",
    "                y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "                run_aucs.append(roc_auc_score(y_val, y_pred_proba))\n",
    "        # If your data is a NumPy array, the original slicing works\n",
    "        else:\n",
    "            for train_idx, val_idx in cv_run.split(config['X'], y_train):\n",
    "                X_tr, X_val = config['X'][train_idx], config['X'][val_idx]\n",
    "                y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "                model = clone(config['model'])\n",
    "\n",
    "                if config['X_unlabeled'] is not None:\n",
    "                    model.fit(X_tr, y_tr, X_u=config['X_unlabeled'])\n",
    "                else:\n",
    "                    model.fit(X_tr, y_tr)\n",
    "\n",
    "                y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "                run_aucs.append(roc_auc_score(y_val, y_pred_proba))\n",
    "\n",
    "        aucs.append(np.mean(run_aucs))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    all_scores[config_name] = aucs\n",
    "\n",
    "    ablation_results.append({\n",
    "        'Configuration': config_name,\n",
    "        'Mean AUC': f\"{np.mean(aucs):.4f}\",\n",
    "        'Std Dev AUC': f\"{np.std(aucs):.4f}\",\n",
    "        'Runtime (s)': f\"{end_time - start_time:.2f}\"\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "ablation_df = pd.DataFrame(ablation_results)\n",
    "print(\"\\nðŸ“Š Ablation Study Results:\")\n",
    "print(ablation_df.to_string(index=False))\n",
    "\n",
    "# --- 5. Statistical Significance Testing (Wilcoxon Signed-Rank Test) ---\n",
    "print(\"\\nðŸ§  Statistical Significance Testing (Wilcoxon Signed-Rank Test on AUC):\")\n",
    "print(\"H0: Medians of both distributions are equal.\")\n",
    "print(\"p-value < 0.05 indicates a statistically significant difference.\")\n",
    "\n",
    "comparisons = [\n",
    "    ('Base', 'Base + SSL'),\n",
    "    ('Base + SSL + Poly', 'Full Model'),\n",
    "    ('Self-Training', 'Full Model')\n",
    "]\n",
    "for config1, config2 in comparisons:\n",
    "    if config1 in all_scores and config2 in all_scores:\n",
    "        scores1 = all_scores[config1]\n",
    "        scores2 = all_scores[config2]\n",
    "        statistic, p_value = stats.wilcoxon(scores1, scores2)\n",
    "        print(f\"\\n  - {config1} vs {config2}:\")\n",
    "        print(f\"    p-value = {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"    -> The difference is statistically significant.\")\n",
    "        else:\n",
    "            print(\"    -> The difference is NOT statistically significant.\")\n",
    "    else:\n",
    "        print(f\"Skipping comparison: '{config1}' or '{config2}' not found in results.\")\n",
    "\n",
    "# --- 6. Component Contributions to AUC ---\n",
    "print(\"\\nðŸ“ˆ Component Contributions to AUC (relative to Base Model):\")\n",
    "base_auc = np.mean(all_scores['Base'])\n",
    "ssl_improvement = np.mean(all_scores['Base + SSL']) - base_auc\n",
    "full_model_improvement = np.mean(all_scores['Full Model']) - base_auc\n",
    "\n",
    "print(f\"  - Base AUC: {base_auc:.4f}\")\n",
    "print(f\"  - SSL contribution: +{ssl_improvement:.4f}\")\n",
    "print(f\"  - Full model improvement over Base: +{full_model_improvement:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Script execution completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
